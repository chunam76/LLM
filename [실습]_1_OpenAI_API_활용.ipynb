{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chunam76/LLM/blob/main/%5B%EC%8B%A4%EC%8A%B5%5D_1_OpenAI_API_%ED%99%9C%EC%9A%A9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c4fca33",
      "metadata": {
        "id": "2c4fca33"
      },
      "source": [
        "# [실습] OpenAI API 써보기\n",
        "\n",
        "\n",
        "OpenAI API를 통해 OpenAI의 기능을 호출하고 활용할 수 있습니다.   \n",
        "\n",
        "[여기](https://platform.openai.com/account/api-keys)를 클릭하여 API 키를 생성할 수 있습니다.   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "caf3f24a",
      "metadata": {
        "id": "caf3f24a"
      },
      "outputs": [],
      "source": [
        "!pip install openai tiktoken --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbf3969a",
      "metadata": {
        "id": "cbf3969a"
      },
      "outputs": [],
      "source": [
        "!pip show openai\n",
        "# 버전 확인하는 코드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afecf897",
      "metadata": {
        "id": "afecf897"
      },
      "outputs": [],
      "source": [
        "# os의 환경 변수에 API 키 복사 붙여넣기\n",
        "import openai\n",
        "import os\n",
        "\n",
        "# OPENAI API KEY 설정\n",
        "os.environ['OPENAI_API_KEY']=\"\"\n",
        "\n",
        "client = openai.OpenAI()\n",
        "\n",
        "\n",
        "assert len(os.environ['OPENAI_API_KEY']) > 0, \"OPENAI_API_KEY가 환경 변수에 설정되어 있지 않습니다. API 키를 설정해주세요.\"\n",
        "\n",
        "# API 키가 설정되어 있다면, 이 지점 이후의 코드가 실행됩니다.\n",
        "print(\"OPENAI_API_KEY가 정상적으로 설정되어 있습니다.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7546bc5",
      "metadata": {
        "id": "b7546bc5"
      },
      "source": [
        "client를 통해 openAI의 기능을 사용할 수 있습니다.      \n",
        "\n",
        "사용 가능한 모델의 목록은 https://platform.openai.com/docs/models 에서 확인 가능합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0326bb3",
      "metadata": {
        "id": "d0326bb3"
      },
      "source": [
        "<br><br><br>\n",
        "openai의 LLM 모델은 현재 다음의 모델 사용이 가능합니다.\n",
        "\n",
        "- gpt-4o-2024-08-06 (gpt-4o의 최신 버전)\n",
        "- gpt-4o (128k, Tokenizer 개선)\n",
        "<br><br>\n",
        "- gpt-4o-mini (128k, Tokenizer 개선)\n",
        "<br><br>\n",
        "- gpt-4-turbo (128k)\n",
        "\n",
        "---\n",
        "- gpt-3.5-turbo (16k Context Window)\n",
        "\n",
        "- gpt-3.5-turbo-instruct (Legacy)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c100e73",
      "metadata": {
        "id": "7c100e73"
      },
      "source": [
        "3.5 instruct 모델을 제외하고, 모든 모델은 Chat 모델에 해당합니다.   \n",
        "Chat 모델은 채팅 메시지 형태로 데이터를 전달해야 합니다.\n",
        "\n",
        "#### Message의 구성    \n",
        "\n",
        "하나의 채팅 메시지는 `role`과 `content` 조합으로 구성됩니다.   \n",
        "`role`에 따라 system, user, assistant 메시지로 나누어집니다.   \n",
        "\n",
        "시스템 메시지는 GPT의 행동을 지정합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a4e3dfd",
      "metadata": {
        "id": "5a4e3dfd"
      },
      "outputs": [],
      "source": [
        "system_prompt = '당신은 모든 대화를 반말과 단답형으로만 합니다.'\n",
        "\n",
        "messages = [\n",
        "    {'role':'system', 'content': system_prompt},\n",
        "    # GPT 기본 프롬프트: You are a helpful assistant.\n",
        "\n",
        "\n",
        "    {'role':'user', 'content':'당신은 누구입니까?'}\n",
        "    # user message\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f4b4502",
      "metadata": {
        "id": "4f4b4502"
      },
      "source": [
        "메시지 목록을 전달하여, GPT API를 호출합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c42c39be",
      "metadata": {
        "id": "c42c39be"
      },
      "outputs": [],
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages = messages,\n",
        ")\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfcb2038",
      "metadata": {
        "id": "dfcb2038"
      },
      "outputs": [],
      "source": [
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30709eb7",
      "metadata": {
        "id": "30709eb7"
      },
      "source": [
        "temperature, max_tokens 등의 파라미터를 설정할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {'role':'system', 'content':system_prompt},\n",
        "\n",
        "    {'role':'user', 'content':'당신은 몇 년까지의 데이터로 학습되었나요?'}\n",
        "]"
      ],
      "metadata": {
        "id": "YsM-gEGsElO7"
      },
      "id": "YsM-gEGsElO7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4375172",
      "metadata": {
        "id": "c4375172"
      },
      "outputs": [],
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages = messages,\n",
        "    temperature=0.2,\n",
        "    # temperature: 무작위 출력을 조절: (0-2) 0에 가까울수록 정해진 답변을 수행\n",
        "\n",
        "    max_tokens = 512,\n",
        "    # 출력 최대 토큰 수 조절: 초과할 경우 자름\n",
        "\n",
        "    # n = 4\n",
        "    # 여러 개의 출력 가능\n",
        "\n",
        ")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7543aeab",
      "metadata": {
        "id": "7543aeab"
      },
      "outputs": [],
      "source": [
        "# n != 1 이면 여러 개의 결과 생성\n",
        "\n",
        "for msg in response.choices:\n",
        "    print(msg.message.content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09167dc6",
      "metadata": {
        "id": "09167dc6"
      },
      "source": [
        "<br><br><br>\n",
        "### tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d20c84fa",
      "metadata": {
        "id": "d20c84fa"
      },
      "source": [
        "ChatCompletion의 출력 결과를 보면, usage에 토큰 개수가 저장됩니다.   \n",
        "토큰의 개수는 모델이 사용하는 토크나이저마다 다르며,   \n",
        "토큰의 길이는 출력 속도/메모리 사용량/API 요금에 영향을 미칩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29639be0",
      "metadata": {
        "id": "29639be0"
      },
      "source": [
        "tiktoken을 이용하면 모델별 토크나이저를 확인하고, 토큰의 개수를 구할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e1887c7",
      "metadata": {
        "id": "5e1887c7"
      },
      "outputs": [],
      "source": [
        "import tiktoken\n",
        "\n",
        "tokenizer = tiktoken.encoding_for_model(\"gpt-3.5-turbo-instruct\")\n",
        "tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fca177d",
      "metadata": {
        "id": "3fca177d"
      },
      "outputs": [],
      "source": [
        "prompt = 'GPT 모델별 토크나이저를 확인하고, 프롬프트 토큰의 개수를 구할 수 있습니다.'\n",
        "tokens = tokenizer.encode(prompt)\n",
        "print(tokens)\n",
        "print('총 글자 수:',len(prompt))\n",
        "print('총 토큰 수:',len(tokens))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d336a5b7",
      "metadata": {
        "id": "d336a5b7"
      },
      "source": [
        "GPT-4o 모델은 개선된 토크나이저를 지원합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94b0d169",
      "metadata": {
        "id": "94b0d169"
      },
      "outputs": [],
      "source": [
        "tokenizer_4o = tiktoken.encoding_for_model(\"gpt-4o\")\n",
        "tokenizer_4o"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "794dd41d",
      "metadata": {
        "id": "794dd41d"
      },
      "outputs": [],
      "source": [
        "prompt = 'GPT 모델별 토크나이저를 확인하고, 프롬프트 토큰의 개수를 구할 수 있습니다.'\n",
        "\n",
        "# GPT4o : 줄어든 토큰 수\n",
        "\n",
        "tokens= tokenizer_4o.encode(prompt)\n",
        "print(tokens)\n",
        "print('총 글자 수:',len(prompt))\n",
        "print('총 토큰 수:',len(tokens))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f97ca962",
      "metadata": {
        "id": "f97ca962"
      },
      "source": [
        "<br><br><br>\n",
        "### seed\n",
        "LLM은 그 특성상 동일한 input prompt가 들어와도 결과가 항상 다르게 출력되는데,   \n",
        " seed 파라미터는 이를 조절하기 위해 만들어졌습니다.\n",
        "\n",
        "* 출력이 길어지면 결과가 달라집니다. (단일 파라미터로 컨트롤하기는 어려운 것 같습니다..)    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a742fbea",
      "metadata": {
        "id": "a742fbea"
      },
      "outputs": [],
      "source": [
        "# 프롬프트 준비\n",
        "messages = [\n",
        "    {'role':'system', 'content':'당신은 건강한 식단과 식이의 전문가입니다.'},\n",
        "    {'role':'user', 'content':'건강한 생활 패턴을 유지하는 방법은 무엇입니까?'}\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df465be1",
      "metadata": {
        "id": "df465be1"
      },
      "outputs": [],
      "source": [
        "response = client.chat.completions.create(\n",
        "    model = \"gpt-4o-mini\",\n",
        "    messages = messages,\n",
        "    temperature =  0.5,\n",
        "    max_tokens = 500,\n",
        "    seed = 8291\n",
        "\n",
        ")\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c79b11f9",
      "metadata": {
        "id": "c79b11f9"
      },
      "outputs": [],
      "source": [
        "# 같은 코드로 두 번 실행하기 (살짝 달라짐)\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model = \"gpt-4o-mini\",\n",
        "    messages = messages,\n",
        "    temperature =  0.5,\n",
        "    max_tokens = 500,\n",
        "    seed = 8291\n",
        "\n",
        ")\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7fac45c",
      "metadata": {
        "id": "c7fac45c"
      },
      "source": [
        "번역, 코딩 등의 작업도 수행할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2f50ce5",
      "metadata": {
        "id": "f2f50ce5"
      },
      "outputs": [],
      "source": [
        "# 번역\n",
        "prompt = '''한국어 문장: 생성형 AI의 능력이 점점 증가하고 있습니다.\n",
        "영어 문장: '''\n",
        "\n",
        "# 프롬프트 준비\n",
        "messages = [\n",
        "    {'role':'user', 'content':prompt}\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eda71634",
      "metadata": {
        "id": "eda71634"
      },
      "outputs": [],
      "source": [
        "response = client.chat.completions.create(\n",
        "    model = \"gpt-4o-mini\",\n",
        "    messages = messages,\n",
        "    temperature =  0.2,\n",
        "    max_tokens = 500\n",
        "\n",
        ")\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77e23ffa",
      "metadata": {
        "id": "77e23ffa"
      },
      "outputs": [],
      "source": [
        "# 코딩\n",
        "prompt = '''# 주어지는 text 문자열에 대해, 공백을 포함한 특수문자를 모두 제거하는 파이썬 코드\n",
        "text= \"2:0→2:3→4:3→4:4→7:4...'대타 김헌곤 결승타' 삼성, KIA 제압하고 8연패 탈출\"\n",
        "\n",
        "'''\n",
        "\n",
        "messages = [\n",
        "    {'role':'system', 'content':'코드만 출력하세요.'},\n",
        "    {'role':'user', 'content':prompt}\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ce0fa03",
      "metadata": {
        "id": "8ce0fa03"
      },
      "outputs": [],
      "source": [
        "response = client.chat.completions.create(\n",
        "    model = \"gpt-4o-mini\",\n",
        "    messages = messages,\n",
        "    temperature =  0.2,\n",
        "    max_tokens = 500\n",
        "\n",
        ")\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "049ce257",
      "metadata": {
        "id": "049ce257"
      },
      "outputs": [],
      "source": [
        "# 되는지 확인해보기\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fbee135a",
      "metadata": {
        "id": "fbee135a"
      },
      "source": [
        "다양한 시스템 메시지는 출력의 형식을 크게 변화시킵니다.    \n",
        "ChatGPT에서는 user 메시지에 포함하는 내용이지만,    \n",
        "system 메시지에 넣을 경우 더 효과적입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fa3b126",
      "metadata": {
        "id": "0fa3b126"
      },
      "outputs": [],
      "source": [
        "messages = [\n",
        "    {'role':'system', 'content' : '''당신은 공감하거나 격려하지 않으며,\n",
        "상대를 불쾌하게 합니다. 답변은 반말로 하세요.'''},\n",
        "    {'role':'user', 'content':'오늘 회사 가기 싫어.'}\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2753989b",
      "metadata": {
        "id": "2753989b"
      },
      "outputs": [],
      "source": [
        "response = client.chat.completions.create(\n",
        "    model = \"gpt-4o-mini\",\n",
        "    messages = messages,\n",
        "    temperature = 1.0\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "109c888f",
      "metadata": {
        "id": "109c888f"
      },
      "outputs": [],
      "source": [
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9626ef0d",
      "metadata": {
        "id": "9626ef0d"
      },
      "source": [
        "여러 번의 대화를 저장할 수도 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "069ab1e5",
      "metadata": {
        "id": "069ab1e5"
      },
      "outputs": [],
      "source": [
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-4o-mini\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Where was it played?\"}\n",
        "  ]\n",
        ")\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49ecd209",
      "metadata": {
        "id": "49ecd209"
      },
      "source": [
        "만약 대화를 계속 이어나가고 싶다면 어떻게 하면 될까요?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fbb11496",
      "metadata": {
        "id": "fbb11496"
      },
      "source": [
        "입력과 그 결과를 받아, 형식을 맞춰서 messages에 저장하면 됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23e8cbca",
      "metadata": {
        "id": "23e8cbca"
      },
      "source": [
        "## 실습) Multi-turn Conversation    \n",
        "아래의 코드는 반복문을 이용해 연속적인 대화를 수행하는 코드의 일부입니다.    \n",
        "새로운 입력(`input()`)과 모델의 출력(`ai_msg`)을 이용해  \n",
        "연속적인 대화를 이어갈 수 있도록 코드를 수정하세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e65eaaf",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3e65eaaf"
      },
      "outputs": [],
      "source": [
        "system_prompt = '당신은 모든 것에 부정적입니다. 답변은 반말로 하세요.'\n",
        "# 다른 프롬프트로 바꾸셔도 됩니다\n",
        "\n",
        "history = [\n",
        "  {\"role\": \"system\", \"content\": system_prompt},\n",
        "]\n",
        "\n",
        "# 입력을 4번 수행해야 종료됩니다 (ESC로 중간 종료 가능)\n",
        "\n",
        "for i in range(4):\n",
        "    usr_msg = input() # 사용자 대화 입력\n",
        "\n",
        "    print (\"User:\",usr_msg) # 그대로 출력\n",
        "\n",
        "    # TODO: history에 형식 맞춰서 usr_msg append 하기\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model = \"gpt-4o-mini\",\n",
        "        messages = history\n",
        "    )\n",
        "    # ai msg 생성\n",
        "\n",
        "    ai_msg = response.choices[0].message.content\n",
        "\n",
        "    print(\"AI:\", ai_msg) # 그대로 출력\n",
        "\n",
        "    # TODO: history에 형식 맞춰서 ai_msg append 하기\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Structured Chat (24.08.06)   \n",
        "\n",
        "GPT-4o의 최신 버전은 구조화된 출력을 제공합니다."
      ],
      "metadata": {
        "id": "rrLmpck0PDiX"
      },
      "id": "rrLmpck0PDiX"
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel\n",
        "\n",
        "class DrugDesc(BaseModel):\n",
        "    성분명: str\n",
        "    증상: list[str]\n",
        "    주의사항: list[str]\n",
        "\n",
        "class DrugInfo(BaseModel):\n",
        "    약: list[DrugDesc]\n",
        "\n",
        "completion = client.beta.chat.completions.parse(\n",
        "    model = \"gpt-4o-2024-08-06\",\n",
        "    messages = [\n",
        "        {'role':'system', 'content':'다음 데이터를 분석하세요. 새로운 내용을 추가하지 마세요.'},\n",
        "\n",
        "        {\"role\": \"user\", \"content\": \"\"\"아세트아미노펜은 해열진통제이다.\n",
        "발열 및 두통, 신경통, 근육통, 월경통, 염좌통 등을 가라앉히는 데 사용된다.\n",
        "그 외에도 생리통 및 치통, 관절통, 류마티스성 통증 등에도 사용 가능하다.\n",
        "아세트아미노펜 단일 성분으로 이뤄진 약 외에 감기약과 같은 복합제에도 함유되어 있는\n",
        "경우가 많으므로 중복 복용하지 않도록 주의가 필요하다. \"\"\"},\n",
        "\n",
        "        {\"role\":'user', 'content':'''미다졸람은 벤조디아제핀 계열에 속하는 약물이다.\n",
        "뇌에서 억제성 신경전달물질의 작용을 강화시켜 진정효과를 나타내는 약물이다.\n",
        "효과가 빠르게 나타나고 짧은 시간 동안 효과가 지속된다.\n",
        "내시경검사나 수술 전에 진정 목적으로 사용된다.\n",
        "졸음이나 주의력 저하 등의 부작용을 유발할 수 있으므로\n",
        "투여 후 자동차 운전이나 위험한 기계 조작을 하지 않도록 한다.'''}],\n",
        "\n",
        "    response_format= DrugInfo,\n",
        ")\n",
        "\n",
        "druginfo = completion.choices[0].message.parsed\n",
        "\n",
        "druginfo"
      ],
      "metadata": {
        "id": "ZH6J723aPYoD"
      },
      "id": "ZH6J723aPYoD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "8dcbea7f",
      "metadata": {
        "id": "8dcbea7f"
      },
      "source": [
        "### Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9bd29d13",
      "metadata": {
        "id": "9bd29d13"
      },
      "source": [
        "임베딩은 텍스트를 벡터로 변환합니다.   \n",
        "OpenAI는 3개의 임베딩 모델을 지원합니다.\n",
        "\n",
        "- text-embedding-3-large\n",
        "- text-embedding-3-small\n",
        "- text-embedding-ada-002 (구버전, 기본값)\n",
        "\n",
        "\n",
        "#### 임베딩의 활용 예시)\n",
        "- 검색 : 입력 쿼리와 데이터베이스 문장들 간의 관련도 계산하여 순위 매기기\n",
        "- 추천 : 텍스트의 연관성을 기준으로 추천하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2360da9b",
      "metadata": {
        "id": "2360da9b"
      },
      "outputs": [],
      "source": [
        "emb = client.embeddings.create(\n",
        "    model = 'text-embedding-3-large',\n",
        "    input = '삼성SDS, 생성형 AI 사업 본격화…\"패브릭스\"와 \"브리티 코파일럿\" 기반 공공 디지털 혁신 지원',\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c31a2d9e",
      "metadata": {
        "id": "c31a2d9e"
      },
      "outputs": [],
      "source": [
        "emb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3918b326",
      "metadata": {
        "id": "3918b326"
      },
      "outputs": [],
      "source": [
        "emb.data[0].embedding[0:3]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d5d6090",
      "metadata": {
        "id": "4d5d6090"
      },
      "source": [
        "방금 넣은 문장의 임베딩을 다른 문장들의 임베딩과 비교해 보겠습니다.   \n",
        "아래의 코드는 다소 길지만, 실제 어플리케이션에서는 코드 한 두 줄로 표현할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad2d8343",
      "metadata": {
        "id": "ad2d8343"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# 입력 텍스트의 임베딩 생성\n",
        "query = '삼성SDS, 생성형 AI 사업 본격화…\"패브릭스\"와 \"브리티 코파일럿\" 기반 공공 디지털 혁신 지원'\n",
        "\n",
        "response = client.embeddings.create(\n",
        "    input=query,\n",
        "    model=\"text-embedding-3-large\"\n",
        ")\n",
        "\n",
        "query_emb = response.data[0].embedding\n",
        "query_emb = np.array(query_emb).astype(\"float32\") # 계산을 빠르게 하기 위해서\n",
        "\n",
        "# 대상 텍스트의 임베딩 생성\n",
        "target_texts = [\n",
        "    \"신한투자-'삼성SDS, 생성형AI 솔루션으로 성장모멘텀…목표가↑'\",\n",
        "    \"AI가 年 310조 경제효과 창출…정부, AI 일상화에 7102억 투입\",\n",
        "    \"1114회 로또 1등 각 15억원씩…1곳서 수동 5명(종합)\",\n",
        "    \"교보증권, 디지털 전환 가속화…생성형 AI 활용 사내교육 실시\"\n",
        "]\n",
        "\n",
        "# 4개 문장의 임베딩 생성\n",
        "response_candidates = client.embeddings.create(\n",
        "    input=target_texts,\n",
        "    model=\"text-embedding-3-large\"\n",
        ")\n",
        "\n",
        "\n",
        "target_embeds = [record.embedding for record in response_candidates.data] # 4개의 임베딩 저장\n",
        "target_embeds = np.array(target_embeds).astype(\"float32\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8ee21be",
      "metadata": {
        "id": "c8ee21be"
      },
      "outputs": [],
      "source": [
        "# 코사인 유사도 계산\n",
        "def cosine_similarity(embedding1, embedding2):\n",
        "    dot_product = np.dot(embedding1, embedding2.T)\n",
        "    norm1 = np.linalg.norm(embedding1)\n",
        "    norm2 = np.linalg.norm(embedding2, axis=1)\n",
        "    similarity = dot_product / (norm1 * norm2)\n",
        "    return 1 -similarity\n",
        "\n",
        "# 유클리드 거리 계산\n",
        "def euclidean_distance(embedding1, embedding2):\n",
        "    distances = np.linalg.norm(embedding2 - embedding1, axis=1)\n",
        "    return distances\n",
        "\n",
        "# query_emb와 target_embeds의 코사인 거리 계산\n",
        "cosine_distances = cosine_similarity(query_emb, target_embeds)\n",
        "\n",
        "# query_emb와 target_embeds의 유클리드 거리 계산\n",
        "euclidean_distances = euclidean_distance(query_emb, target_embeds)\n",
        "\n",
        "\n",
        "print('Query:',query)\n",
        "print('---')\n",
        "\n",
        "\n",
        "for i, (cosine_distance, euclidean_distance) in enumerate(zip(cosine_distances, euclidean_distances)):\n",
        "    print(target_texts[i])\n",
        "    print(f\"코사인 거리: {cosine_distance:.4f}\")\n",
        "    print(f\"유클리드 거리: {euclidean_distance:.4f}\")\n",
        "    print('---')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32c5c048",
      "metadata": {
        "id": "32c5c048"
      },
      "source": [
        "문제의 질문에 가장 가까웠던 텍스트는 첫 번째 텍스트라는 것을 확인할 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "581ddb73",
      "metadata": {
        "id": "581ddb73"
      },
      "source": [
        "## 이미지 생성 (DALL-E 3)\n",
        "DALL-E 는 OpenAI의 이미지 생성 인공지능입니다.   \n",
        "prompt에 원하는 그림의 묘사를 넣으면 생성 가능합니다.\n",
        "\n",
        "`dall-e-2`, `dall-e-3`를 사용 가능합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f981d3b7",
      "metadata": {
        "id": "f981d3b7"
      },
      "outputs": [],
      "source": [
        "# 계정당 8~16회 /1분 제한\n",
        "\n",
        "response  = client.images.generate(\n",
        "  model=\"dall-e-3\",\n",
        "  prompt=\"\"\"An elephant with a space suit, flowing through the space with stars and planets.\n",
        "The elephant is smiling and has a happy face.\"\"\",\n",
        "  n=1,\n",
        "  size=\"1024x1024\"\n",
        ")\n",
        "response"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84daea0e",
      "metadata": {
        "id": "84daea0e"
      },
      "source": [
        "response에는 생성된 그림의 링크가 포함되어 있습니다.    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "122dc51a",
      "metadata": {
        "id": "122dc51a",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "image_link = response.data[0].url\n",
        "image_link"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfab5ad5",
      "metadata": {
        "id": "dfab5ad5"
      },
      "source": [
        "revised_prompt는 사용자의 프롬프트를 더 자세하게 수정합니다.   \n",
        "이는 Dall-E 3 에서 제안한 기술입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7bac3fda",
      "metadata": {
        "id": "7bac3fda"
      },
      "outputs": [],
      "source": [
        "print(response.data[0].revised_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd63bc4b",
      "metadata": {
        "id": "dd63bc4b"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image\n",
        "import requests\n",
        "\n",
        "# 이미지 출력\n",
        "img = Image(url = image_link)\n",
        "response = requests.get(image_link)\n",
        "\n",
        "# 이미지를 파일로 저장\n",
        "with open('your_image.png', 'wb') as file:\n",
        "    file.write(response.content)\n",
        "\n",
        "img\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6cbef53",
      "metadata": {
        "id": "d6cbef53"
      },
      "source": [
        "##  이미지 프롬프트 전달하기\n",
        "\n",
        "이미지 파일을 OpenAI에 전달하여 프롬프트에 추가할 수도 있습니다.   \n",
        "content에 image_url이나 base64로 불러온 이미지를 전달하면 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2002cf6",
      "metadata": {
        "id": "a2002cf6"
      },
      "outputs": [],
      "source": [
        "# 링크로 이미지 전달하기\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": [\n",
        "        {\"type\": \"text\",\n",
        "                 \"text\": \"이 그림을 묘사하고, 일반적인 그림과 비교해서 특이한 점을 언급하세요.\"\n",
        "        },\n",
        "\n",
        "        {\"type\": \"image_url\",\n",
        "                \"image_url\": {\"url\": image_link}\n",
        "        },\n",
        "    ]}\n",
        "\n",
        "]\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model = \"gpt-4o-mini\",\n",
        "    messages = messages,\n",
        "    max_tokens = 1024,\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd7d2195",
      "metadata": {
        "id": "fd7d2195",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# 오프라인 이미지 base64로 로드하여 저장하기\n",
        "import base64\n",
        "\n",
        "def encode_image(image_path):\n",
        "  with open(image_path, \"rb\") as image_file:\n",
        "    return base64.b64encode(image_file.read()).decode('utf-8')\n",
        "\n",
        "# 이미지 경로\n",
        "image_path = \"your_image.png\"\n",
        "base64_image = encode_image(image_path)\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": [\n",
        "        {\"type\": \"text\",\n",
        "                 \"text\": \"이 그림엔 무엇이 있나요?\"\n",
        "        },\n",
        "\n",
        "        {\"type\": \"image_url\",\n",
        "                \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}\n",
        "        },\n",
        "    ]}\n",
        "]\n",
        "\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages= messages,\n",
        "    max_tokens=1024,\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02963620",
      "metadata": {
        "id": "02963620"
      },
      "source": [
        "------"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0cf8deca",
      "metadata": {
        "id": "0cf8deca"
      },
      "source": [
        "<br><br><br>\n",
        "\n",
        "# Voice API(음성 API)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6cbfb356",
      "metadata": {
        "id": "6cbfb356"
      },
      "source": [
        "OpenAI의 TTS와 Whisper를 사용할 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "227101fc",
      "metadata": {
        "id": "227101fc"
      },
      "source": [
        "## Text-to-speech (텍스트 음성 변환, TTS)    \n",
        "\n",
        "모델과 목소리(alloy, echo, fable, onyx, nova, shimmer), input을 입력하면 음성 파일을 생성합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6512244f",
      "metadata": {
        "id": "6512244f"
      },
      "outputs": [],
      "source": [
        "speech_file_path = \"./test.mp3\"\n",
        "response = client.audio.speech.create(\n",
        "  model=\"tts-1\", #\"tts-1-hd\" : 2x price, HD\n",
        "  voice=\"nova\",\n",
        "  input=\"\"\"LLM은 Large Language Model의 약자입니다. 대용량의 코퍼스를 학습시킨 머신 러닝 모델로,\n",
        "LLama 3.1, Mistral 2 Large, Grok 2가 최근 출시되었습니다.\"\"\"\n",
        ")\n",
        "\n",
        "response.stream_to_file(speech_file_path)\n",
        "# 저장"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e99d313",
      "metadata": {
        "id": "3e99d313"
      },
      "source": [
        "## Speech-to-Text (음성 인식)   \n",
        "\n",
        "OpenAI의 Whisper는 오디오 파일을 글자로 변환하는 전사(Transcription) 기능을 지원합니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ccc5a903",
      "metadata": {
        "id": "ccc5a903"
      },
      "source": [
        "pyaudio와 wave를 이용하여 음성을 녹음할 수 있습니다.\n",
        "\n",
        "-- **코랩에서는 아래의 코드가 실행되지 않으므로, 녹음 대신 위에서 만든 파일을 활용하겠습니다.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "013930d2",
      "metadata": {
        "id": "013930d2"
      },
      "outputs": [],
      "source": [
        "# 관련 라이브러리 설치\n",
        "# !pip install pyaudio wave"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a71e4ce5",
      "metadata": {
        "id": "a71e4ce5"
      },
      "outputs": [],
      "source": [
        "# import pyaudio\n",
        "# import wave\n",
        "\n",
        "# # 녹음 설정\n",
        "# FORMAT = pyaudio.paInt16  # 오디오 형식\n",
        "# CHANNELS = 1  # 모노 오디오\n",
        "# RATE = 44100  # 샘플링 레이트 (Hz)\n",
        "# CHUNK = 1024  # 버퍼 크기\n",
        "# RECORD_SECONDS = 5  # 녹음 시간 (초)\n",
        "# OUTPUT_FILENAME = \"recorded_audio.wav\"  # 저장할 파일 이름\n",
        "\n",
        "# # PyAudio 초기화\n",
        "# audio = pyaudio.PyAudio()\n",
        "\n",
        "# # 오디오 스트림 열기\n",
        "# stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
        "#                     rate=RATE, input=True,\n",
        "#                     frames_per_buffer=CHUNK)\n",
        "\n",
        "# print(\"녹음 중...\")\n",
        "\n",
        "# frames = []\n",
        "\n",
        "# # 녹음 데이터 수집\n",
        "# for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
        "#     data = stream.read(CHUNK)\n",
        "#     frames.append(data)\n",
        "\n",
        "# print(\"녹음 완료!\")\n",
        "\n",
        "# # 오디오 스트림 닫기\n",
        "# stream.stop_stream()\n",
        "# stream.close()\n",
        "# audio.terminate()\n",
        "\n",
        "# # WAV 파일로 저장\n",
        "# with wave.open(OUTPUT_FILENAME, 'wb') as wf:\n",
        "#     wf.setnchannels(CHANNELS)\n",
        "#     wf.setsampwidth(audio.get_sample_size(FORMAT))\n",
        "#     wf.setframerate(RATE)\n",
        "#     wf.writeframes(b''.join(frames))\n",
        "\n",
        "# print(f\"녹음된 오디오가 '{OUTPUT_FILENAME}' 파일로 저장되었습니다.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "323957e0",
      "metadata": {
        "id": "323957e0"
      },
      "source": [
        "녹음된 파일의 경로를 집어넣어, 전사(transcript)를 수행합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ad8923e",
      "metadata": {
        "id": "3ad8923e"
      },
      "outputs": [],
      "source": [
        "audio_file= open(\"./test.mp3\", \"rb\")\n",
        "transcript = client.audio.transcriptions.create(\n",
        "  model = \"whisper-1\",\n",
        "  file = audio_file\n",
        "  # prompt = 'Llama 3.1, Mistral 2 Large, Groq 2'\n",
        ")\n",
        "transcript.text"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tbR-C9S1CzT7",
      "metadata": {
        "id": "tbR-C9S1CzT7"
      },
      "source": [
        "Transcription API의 결과를 프롬프트에 포함하면    \n",
        "음성 데이터를 활용한 어플리케이션을 만들 수도 있습니다."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}